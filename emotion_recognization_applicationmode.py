# -*- coding: utf-8 -*-
"""emotion_recognization_ApplicationMode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G9syJlCNhpyuyqnhbEFxSKUCtngEc7J0
"""

import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
import torch.utils.data as td
from torchvision import datasets, transforms
from torchsummary import summary
import cv2
import numpy as np
import torch.cuda as cuda
from matplotlib import pyplot as plt
from PIL import Image, ImageEnhance

from google.colab import drive
drive.mount('/content/drive')

class CNN_Varient_1(nn.Module):
  def __init__(self,num_classes,kernel_size):
    self.kernel_size = kernel_size
    self.padding =1
    self.num_classes = num_classes


    #Initialize the parent class
    super(CNN_Varient_1,self) .__init__()


    self.conv_layer = nn.Sequential(

      #convolution layer-1
      nn.Conv2d(in_channels=1, out_channels=64, kernel_size=self.kernel_size, padding=1),
      nn.LeakyReLU(inplace=True),
      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=self.kernel_size, padding=1),
      nn.LeakyReLU(inplace=True),
      nn.MaxPool2d(kernel_size=2, stride=2),

      #convolution layer -2
      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=self.kernel_size, padding=1),
      nn.LeakyReLU(inplace=True),
      nn.Conv2d(in_channels=128, out_channels=128, kernel_size=self.kernel_size, padding=1),
      nn.LeakyReLU(inplace=True),
      nn.MaxPool2d(kernel_size=2, stride=2),

      # convolution layer 3
      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=self.kernel_size, padding=1),
      nn.LeakyReLU(inplace=True),
      nn.Conv2d(in_channels=256, out_channels=256, kernel_size=self.kernel_size, padding=1),
      nn.LeakyReLU(inplace=True),
      nn.MaxPool2d(kernel_size=2, stride=2),

      )

    self.fc_layer = nn.Sequential(

      nn.Linear(9216 , 1024),
      nn.ReLU(inplace=True),
      nn.Dropout(p=0.5),

      nn.Linear(1024, 512),
      nn.ReLU(inplace=True),
      nn.Dropout(p=0.5),
      nn.Linear(512, self.num_classes),




    )
  def forward(self, x):
      # conv layers
      x = self.conv_layer(x)
      # flatten
      x = x.view(x.size(0), -1)
      # fc layer
      x = self.fc_layer(x)
      return x


model1_1 = CNN_Varient_1(kernel_size=3,num_classes=4)
# print(model1)

if cuda.is_available():
  model1_1 = model1_1.cuda()

summary(model1_1, (1, 48, 48))

model_path = '/content/drive/MyDrive/AI Project/Saved_model/main_model.pth'
if cuda.is_available():
  loaded_model = CNN_Varient_1(kernel_size=3,num_classes=4)
  loaded_model.load_state_dict(torch.load(model_path))

loaded_model.eval()

# for param in model.parameters():
#   print(param)

def preprocess_images(test_image_path):
  test_image = cv2.imread(test_image_path)
  test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)
  test_image = cv2.resize(test_image, (48, 48))

  test_img_data = np.array(test_image)
  test_img_data = test_img_data.astype('float32')
  test_img_data = test_img_data/255

  input_image = torch.from_numpy(test_img_data)

  input_image = input_image.unsqueeze(0)


  input_image = input_image.repeat(1, 1, 1, 1)
  # print(input_image.shape)
  return input_image

def predict_class(preprocessed_input_image):

  with torch.no_grad():
    output = loaded_model(preprocessed_input_image)
  _, predicted = torch.max(output.data, 1)

  class_map = {0 : "angry", 1: "bored",2: "neutral",3: "focused"}
  predicted_class_index = int(predicted.item())

  predicted_class_name = class_map.get(predicted_class_index)
  print("Pridicted_class:",predicted_class_name)
  return predicted_class_name

#for pridicting single image

test_image_path = '/content/drive/MyDrive/AI Project/focused_1.jpg'
preprocessed_input_image = preprocess_images(test_image_path)
Predicted_output= predict_class(preprocessed_input_image)

img = Image.open(test_image_path).convert('L')
img = img.resize((48, 48))

plt.figure(figsize=(1.5, 1.5))
plt.imshow(img, cmap = 'gray')
plt.title(f"true='focused', pred='{Predicted_output}'",fontsize=7)
plt.axis('off')

plt.show()

images = ['angry_1.jpg','angry_3.jpg','angry_2.jpg','bored_1.jpg','bored_2.jpg','bored_3.jpg','neutral_1.jpg','neutral_2.jpg','neutral_3.jpg','focused_1.jpg']
true_label = ["angry","angry","angry","bored","bored","bored","neutral","neutral","neutral","focused"]

# Showing Sample images for testing
fig, axes = plt.subplots(2, 5, figsize=(9, 4))

for i, ax in enumerate(axes.flat):
  # for i,image in enumarate(images):
    BASE_PATH = "/content/drive/MyDrive/AI Project/"
    test_image_path = BASE_PATH + images[i]
    # print(test_image_path)
    preprocessed_input_image = preprocess_images(test_image_path)
    Predicted_output= predict_class(preprocessed_input_image)
    # print(Predicted_output)

    img = Image.open(test_image_path).convert('L')
    img = img.resize((48, 48))

    # Display the image
    ax.imshow(img, cmap = 'gray')
    ax.set_title(f"true='{true_label[i]}', pred='{Predicted_output}'",fontsize=7)
    ax.axis('off')

# Adjust the spacing between subplots
plt.tight_layout()
plt.subplots_adjust(wspace=0.6)
# Display the grid of images
plt.show()

